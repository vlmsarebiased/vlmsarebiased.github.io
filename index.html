<!DOCTYPE html>
<html>
<head>
  <!-- Google tag (gtag.js) - Add this first! -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-R57GVTJBR9"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-R57GVTJBR9');
  </script>

  <!-- Enhanced tracking for research project -->
  <script>
    // Track paper downloads
    function trackPaperDownload() {
      gtag('event', 'download', {
        'event_category': 'Paper',
        'event_label': 'ArXiv PDF',
        'value': 1
      });
    }

    // Track code repository visits
    function trackCodeVisit() {
      gtag('event', 'click', {
        'event_category': 'Code',
        'event_label': 'GitHub Repository',
        'value': 1
      });
    }

    // Track dataset visits
    function trackDatasetVisit() {
      gtag('event', 'click', {
        'event_category': 'Dataset',
        'event_label': 'Hugging Face Dataset',
        'value': 1
      });
    }

    // Track examples visits
    function trackExamplesVisit() {
      gtag('event', 'click', {
        'event_category': 'Examples',
        'event_label': 'GitHub Examples',
        'value': 1
      });
    }

    // Track discussion visits
    function trackDiscussionVisit() {
      gtag('event', 'click', {
        'event_category': 'Discussion',
        'event_label': 'X/Twitter Discussion',
        'value': 1
      });
    }
  </script>

  <meta charset="utf-8">
  <meta name="description" content="Vision Language Models are Biased: VLMs fail on simple counting tasks when familiar objects are subtly modified">
  <meta name="keywords" content="VLM, Vision Language Models, Bias, AI, Computer Vision, Counting">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <base href="./" target="_blank">
  <title>VLMs are Biased</title>
  <link rel="icon" href="static/icons/assumption.png" type="image/png">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.2/css/academicons.min.css">

 <style>
/* Base styles - exactly from B-score */
body {
  font-family: 'Noto Sans', sans-serif;
  line-height: 1.6;
  color: #333;
  margin: 0 auto;
  padding: 20px;
  overflow-x: hidden; /* Prevent horizontal scroll */
}

h1, h2, h3, h4, h5 {
  font-family: 'Google Sans', sans-serif;
  font-weight: 700;
  margin-top: 1.5em;
  margin-bottom: 0.5em;
  color: #1a237e;
}

.container {
  max-width: 1200px;
  margin: 0 auto;
  padding: 0 20px;
}

/* Hero section - MODIFIED margin-bottom */
.hero {
  background-color: #f5f7fa;
  padding: 2rem 0;
  margin-bottom: 1rem; /* MODIFIED from 2rem */
}

.hero .title {
  color: #000000;
  font-size: 3.5rem;
  margin-bottom: 1rem;
  font-weight: 700;
  line-height: 1.2;
  display: flex; /* For aligning icon with text */
  align-items: center; /* For aligning icon with text */
  justify-content: center; /* For centering title content */
  flex-wrap: wrap; /* Allow wrapping if title is too long */
}

.hero .title .title-icon {
  height: 0.9em; /* Relative to title font size */
  margin-left: 0.3em;
  vertical-align: middle; /* Better alignment for inline-block/flex item */
}

.publication-authors {
  font-size: 1.2rem;
  line-height: 1.8;
  color: #4a5568;
  margin-bottom: 1rem;
}

.publication-authors .author-block {
  display: inline-block;
  margin: 0 0.4em 0.3em 0;
  margin-right: 10px;
}

.publication-authors .author-block:last-child {
  margin-right: 0;
}

.publication-authors a {
  color: #3182ce;
  text-decoration: none;
}

.publication-authors a:hover {
  text-decoration: underline;
}

.publication-authors sup {
  color: #718096;
  font-weight: normal;
}

.affiliations {
  font-size: 1rem;
  color: #718096;
  margin-bottom: 0.5rem;
}

.contributions {
  font-size: 0.9rem;
  color: #718096;
  margin-bottom: 2rem;
}

/* Buttons - simplified like B-score */
.button {
  display: inline-flex;
  align-items: center;
  padding: 0.75rem 1.5rem; /* Increased padding for bigger buttons */
  border-radius: 4px;
  text-decoration: none;
  font-weight: 600;
  font-size: 1.1rem; /* Increased font size */
  transition: all 0.2s ease;
  border: 1px solid #e2e8f0;
  margin: 0.25rem;
  background-color: #ffffff;
  color: #4a5568;
}
.hero .buttons .button.is-rounded { 
    padding-left: 1.8em; /* Increased padding */
    padding-right: 1.8em;
    padding-top: 0.8em;
    padding-bottom: 0.8em;
}

/* Logo styles for buttons */
.button .logo-icon {
  width: 24px;
  height: 24px;
  margin-right: 0.75rem;
}

.button:hover {
  background-color: #f7fafc;
  border-color: #cbd5e0;
}

.button .icon {
  margin-right: 0.5rem;
}

/* Special styling for the examples button */
.button.is-examples {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: #ffffff;
  border: none;
  box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
  transform: translateY(0);
  transition: all 0.3s ease;
}

.button.is-examples:hover {
  background: linear-gradient(135deg, #5a6fd8 0%, #6a4190 100%);
  transform: translateY(-2px);
  box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
  color: #ffffff;
}
/* Special styling for the discussion button - Slate Gray */
.button.is-discussion {
  background: linear-gradient(135deg, #0987A0 0%, #00C4B3 100%);
  color: #ffffff;
  border: none;
  box-shadow: 0 4px 15px rgba(9, 135, 160, 0.3);
  transform: translateY(0);
  transition: all 0.3s ease;
}

.button.is-discussion:hover {
  background: linear-gradient(135deg, #087387 0%, #00a99a 100%);
  transform: translateY(-2px);
  box-shadow: 0 6px 20px rgba(9, 135, 160, 0.4);
  color: #ffffff;
}

.buttons {
  display: flex;
  justify-content: center;
  flex-wrap: wrap;
  gap: 0.5rem;
}

/* Content sections */
.content-section {
  margin-bottom: 2rem;
  padding: 1rem;
}

.content-section .column ul {
  list-style: disc; 
  margin-left: 1.5em; 
  padding-left: 0.5em; 
}

.content-section .column ul li {
  margin-bottom: 0.5em; 
}

/* UPDATED: Example Gallery Styles */
#example-gallery-section {
  scroll-margin-top: 20px;
}
.gallery-section {
    background: #ffffff;
    border-radius: 12px;
    box-shadow: 0 4px 20px rgba(0,0,0,0.1);
    overflow: hidden;
    border: 1px solid #e2e8f0;
    margin: 2rem 0;
}
.gallery-header {
    background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);
    color: #ffffff;
    padding: 1.5rem;
    text-align: center;
}
.gallery-header h2 {
    color: #ffffff;
    margin: 0;
    font-size: 1.8rem;
}
.gallery-filters {
    padding: 1rem 1.5rem;
    background: #f8fafc;
    border-top: 1px solid #e2e8f0;
    display: flex;
    flex-wrap: wrap;
    justify-content: center;
    gap: 0.5rem;
}

.gallery-filter-btn {
    padding: 0.5rem 1rem;
    background: #ffffff;
    border: 1px solid #e2e8f0;
    border-radius: 20px;
    cursor: pointer;
    transition: all 0.3s ease;
    font-size: 0.85rem;
    font-weight: 500;
    color: #4a5568;
    display: flex;
    align-items: center;
    gap: 0.5rem;
}
.gallery-filter-btn:hover {
  background: #f1f5f9;
  border-color: #cbd5e0;
  transform: translateY(-1px);
}
.gallery-filter-btn.active {
  background: #1a237e;
  color: #ffffff;
  border-color: #1a237e;
}

.gallery-container {
    position: relative;
    padding: 1.5rem 50px;
    background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);
}

.gallery-viewport {
    overflow: hidden;
    position: relative;
    opacity: 1;
    transition: opacity 0.3s ease-in-out;
}

.gallery-track {
    display: flex;
    transition: transform 0.6s cubic-bezier(0.4, 0, 0.2, 1); /* Smoother transition */
}

.gallery-slide {
    flex: 0 0 100%;
    display: flex;
    gap: 1.5rem;
    box-sizing: border-box;
}

.gallery-item {
    flex: 0 0 auto; /* Let JS set the width, don't shrink or grow */
    box-sizing: border-box;
}

.example-card {
    background: #ffffff;
    border-radius: 8px;
    box-shadow: 0 2px 12px rgba(0,0,0,0.08);
    overflow: hidden;
    transition: transform 0.3s ease, box-shadow 0.3s ease;
    border: 1px solid #e2e8f0;
    display: flex;
    flex-direction: column;
    width: 100%;
}
.example-card:hover {
    transform: translateY(-4px);
    box-shadow: 0 4px 20px rgba(0,0,0,0.12);
}
.example-image {
    width: 100%;
    height: 200px;
    position: relative;
    overflow: hidden;
    background: #f1f5f9;
    border-bottom: 1px solid #e2e8f0;
}
.example-image img {
    width: 100%;
    height: 100%;
    object-fit: contain;
    display: block;
}
.image-fallback {
    display: none;
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background: #f1f5f9;
    color: #94a3b8;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    gap: 0.5rem;
    font-size: 0.9rem;
    text-align: center;
    padding: 1rem;
    box-sizing: border-box;
}
.example-image.has-error .image-fallback {
    display: flex;
}
.example-image.has-error img {
    display: none;
}
.example-content {
  padding: 1rem;
  flex-grow: 1;
  display: flex;
  flex-direction: column;
}
.example-question {
    font-size: 0.9rem;
    color: #333;
    line-height: 1.4;
    margin-bottom: 0.8rem;
    flex-grow: 1;
}
.example-info {
    font-size: 0.85rem;
    margin-bottom: 1rem;
    display: flex;
    justify-content: space-between;
    align-items: center;
    flex-wrap: wrap;
    gap: 0.5rem 1rem;
    border: 1px solid #e2e8f0;
    background: #f8fafc;
    padding: 0.6rem;
    border-radius: 6px;
}
.info-label {
    font-weight: 600;
    margin-right: 0.4em;
}
.truth-label { color: #166534; }
.bias-label { color: #991b1b; }
.info-value {
    font-family: 'Courier New', Courier, monospace;
}
.truth-value { color: #15803d; }
.bias-value { color: #b91c1c; }

.example-footer {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-top: auto;
    flex-wrap: wrap;
    gap: 0.5rem;
}
.example-type {
    display: inline-block;
    background: #4a5568;
    color: #ffffff;
    padding: 0.2rem 0.6rem;
    border-radius: 10px;
    font-size: 0.75rem;
    font-weight: 600;
    white-space: nowrap;
}
.copy-prompt-btn, .copy-image-btn {
    background: #e2e8f0;
    border: 1px solid #cbd5e0;
    color: #4a5568;
    padding: 0.3rem 0.7rem;
    font-size: 0.75rem;
    border-radius: 5px;
    cursor: pointer;
    transition: all 0.2s ease;
    display: flex;
    align-items: center;
    gap: 0.3rem;
}
.copy-image-btn {
  background: #dbeafe;
  border-color: #93c5fd;
  color: #1e40af;
}
.copy-prompt-btn:hover {
    background: #cbd5e0;
}
.copy-prompt-btn.copied {
    background: #d1fae5;
    color: #065f46;
    border-color: #6ee7b7;
}

.copy-image-btn:hover {
    background: #bfdbfe;
    border-color: #60a5fa;
}

.copy-image-btn.copied {
    background: #d1fae5;
    color: #065f46;
    border-color: #6ee7b7;
}

.copy-buttons {
    display: flex;
    gap: 0.5rem;
}
.gallery-nav {
    position: absolute;
    top: 50%;
    transform: translateY(-50%);
    background: rgba(255,255,255,0.9);
    border: 1px solid rgba(0,0,0,0.1);
    color: #333;
    width: 40px;
    height: 40px;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    cursor: pointer;
    transition: all 0.3s ease;
    z-index: 10;
    backdrop-filter: blur(5px);
}
.gallery-nav:hover {
    background: white;
    transform: translateY(-50%) scale(1.1);
    box-shadow: 0 2px 8px rgba(0,0,0,0.15);
}
.gallery-nav.prev { left: 5px; } 
.gallery-nav.next { right: 5px; } 

.gallery-indicators {
    display: flex;
    justify-content: center;
    gap: 0.75rem;
    padding: 1.5rem;
    background: #f8fafc;
    border-top: 1px solid #e2e8f0;
}
.gallery-indicator {
    width: 10px;
    height: 10px;
    border-radius: 50%;
    background: #cbd5e0;
    cursor: pointer;
    transition: all 0.3s ease;
}
.gallery-indicator:hover { background: #a0aec0; }
.gallery-indicator.active {
    background: #1a237e;
    transform: scale(1.2);
}
.gallery-paused {
    position: absolute;
    top: 10px;
    right: 10px;
    background: rgba(0,0,0,0.7);
    color: #ffffff;
    padding: 0.3rem 0.8rem;
    border-radius: 12px;
    font-size: 0.75rem;
    font-weight: 600;
    z-index: 10;
    opacity: 0;
    visibility: hidden;
    transition: opacity 0.3s ease, visibility 0.3s ease;
}
.gallery-container:hover .gallery-paused {
    opacity: 1;
    visibility: visible;
}
.highlight-box {
  background-color: #e3f2fd;
  padding: 1.5rem;
  border-radius: 5px;
  margin: 2rem 0;
}
.key-insight {
  background-color: #e8f5e9;
  padding: 1rem;
  border-radius: 5px;
  margin: 1.5rem 0;
}
.stat-highlight {
  background-color: #e3f2fd;
  padding: 1.5rem;
  border-radius: 5px;
  margin: 2rem 0;
  text-align: center;
}
.failure-showcase {
  background-color: #ffebee;
  padding: 1.5rem;
  border-radius: 5px;
  margin: 2rem 0;
}
.methodology-section {
  background-color: #f3e5f5;
  padding: 1.5rem;
  border-radius: 5px;
  margin: 2rem 0;
}
.quote-block {
  border-left: 4px solid #7986cb;
  padding-left: 1rem;
  margin: 1.5rem 0;
  font-style: italic;
}
.results-grid {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
  gap: 1.5rem;
  margin: 2rem 0;
}
.model-result {
  background: #ffffff;
  padding: 1.5rem;
  border-radius: 5px;
  text-align: center;
  box-shadow: 0 2px 8px rgba(0,0,0,0.08);
}
.model-result h4 {
  color: #1a237e;
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 0.5rem;
  margin-bottom: 0.5rem;
}
.research-table {
  background: #ffffff;
  border-radius: 5px;
  box-shadow: 0 2px 8px rgba(0,0,0,0.08);
  margin: 2rem 0;
  overflow-x: auto;
}
.comparison-table table {
  width: 100%;
  border-collapse: collapse;
  min-width: 800px;
}
.comparison-table th {
  background: #4a5568;
  color: #ffffff;
  padding: 0.75rem;
  text-align: center;
  white-space: nowrap;
}
.comparison-table td {
  padding: 0.5rem;
  border-bottom: 1px solid #e2e8f0;
  text-align: center;
}
.comparison-table td:first-child {
  text-align: left;
  font-weight: 600;
  background: #f8fafc;
}
.highlight-value {
  background-color: #fef3c7;
  padding: 0.2rem 0.5rem;
  border-radius: 3px;
  font-weight: 700;
  color: #92400e;
}
.best-value {
  background-color: #d1fae5;
  padding: 0.2rem 0.5rem;
  border-radius: 3px;
  font-weight: 700;
  color: #065f46;
}
.slideshow-container {
  background: #ffffff;
  border-radius: 8px;
  box-shadow: 0 4px 20px rgba(0,0,0,0.1);
  margin: 2rem 0;
  overflow: hidden;
  border: 1px solid #e2e8f0;
}
.slideshow-header {
  background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);
  color: #ffffff;
  padding: 1.5rem;
  position: relative;
}
.slideshow-header-content {
  position: relative;
  z-index: 1;
  display: flex;
  justify-content: space-between;
  align-items: center;
  flex-wrap: wrap;
  gap: 1rem;
}
.slideshow-header h3 {
  color: #ffffff;
  margin: 0;
  font-size: 1.4rem;
}
.slideshow-controls {
  display: flex;
  align-items: center;
  gap: 1rem;
}
.slide-btn {
  background: rgba(255,255,255,0.15);
  border: 1px solid rgba(255,255,255,0.2);
  color: #ffffff;
  width: 38px;
  height: 38px;
  border-radius: 50%;
  cursor: pointer;
  display: flex;
  align-items: center;
  justify-content: center;
  transition: all 0.3s ease;
}
.slide-btn:hover {
  background: rgba(255,255,255,0.25);
  transform: translateY(-1px);
}
.slide-counter {
  color: #ffffff;
  font-weight: 600;
  min-width: 70px;
  text-align: center;
  background: rgba(255,255,255,0.15);
  padding: 0.4rem 1rem;
  border-radius: 20px;
}
.slideshow-content {
position: relative;
min-height: 900px; 
overflow: hidden;
/* Add background to prevent content bleeding */
background: #ffffff;
}

.slide {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    padding: 1.5rem;
    opacity: 0;
    visibility: hidden;
    transition: all 0.8s cubic-bezier(0.4, 0, 0.2, 1);
    display: flex;
    flex-direction: column;
    z-index: 1;
    background: #ffffff; /* Ensure solid background */
}

.slide.active {
    opacity: 1;
    visibility: visible;
    z-index: 10;
}

  .no-slides-message {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      z-index: 5;
      background: #ffffff;
      padding: 2rem;
      border-radius: 8px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
  }
    .slide-image-container {
      width: 100%;
      margin-bottom: 1rem;
    }
    .slide-image {
      width: 100%;
      height: 600px; 
      position: relative;
      border-radius: 8px;
      overflow: hidden;
    }
    .slide-image img {
      width: 100%;
      height: 100%;
      object-fit: contain;
    }
    .image-caption {
      background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);
      color: #ffffff;
      padding: 1rem;
      border-radius: 0 0 8px 8px;
      text-align: center;
      margin-top: -1px; 
    }
    .image-title {
      font-size: 1rem;
      font-weight: 600;
    }
    .image-takeaway {
      font-size: 0.85rem;
      font-style: italic;
    }
    .slide-content {
      width: 100%;
    }
    .domain-tag {
      display: inline-block;
      background: #1a237e;
      color: #ffffff;
      padding: 0.3rem 0.8rem;
      border-radius: 12px;
      font-size: 0.8rem;
      margin-bottom: 0.8rem;
    }
    .accuracy-indicator {
      display: inline-block;
      background: #dc2626;
      color: #ffffff;
      padding: 0.4rem 0.8rem;
      border-radius: 12px;
      font-size: 0.85rem;
      font-weight: 700;
      margin-left: 0.5rem;
    }
    .slideshow-footer {
      background: #f8fafc;
      padding: 1.5rem;
      border-top: 1px solid #e2e8f0;
    }
    .domain-indicators {
      display: flex;
      gap: 0.5rem;
      margin-bottom: 1rem;
      flex-wrap: wrap;
      justify-content: center;
    }
    .domain-indicator {
      padding: 0.5rem 1rem;
      background: #ffffff;
      border: 1px solid #e2e8f0;
      border-radius: 20px;
      cursor: pointer;
    }
    .domain-indicator:hover {
      background: #f1f5f9;
    }
    .domain-indicator.active {
      background: #1a237e;
      color: #ffffff;
    }
    .slideshow-info {
      text-align: center;
      color: #64748b;
      font-size: 0.85rem;
    }
    .research-figure img {
      width: 100%;
      height: auto;
    }
    .research-figure-medium img {
      max-width: 80%; 
      margin: 0 auto;
      display: block; 
    }
    .figure-caption {
      padding: 1rem;
      background: #f8fafc;
      font-size: 0.9rem;
      font-style: italic;
      text-align: center; 
    }
    .figure-caption strong { color: #1a237e; }
    .accuracy-bad { color: #dc2626; font-weight: 700; }
    .accuracy-good { color: #16a34a; font-weight: 700; }
    .truth-value {
      color: #16a34a;
      font-weight: 700;
      background: #f0fdf4;
      padding: 0.2rem 0.5rem;
      border-radius: 3px;
    }
    .error-value {
      color: #dc2626;
      font-weight: 700;
      background: #fef2f2;
      padding: 0.2rem 0.5rem;
      border-radius: 3px;
    }
    .yellow-highlight {
      background: #fef3c7;
      padding: 0.1em 0.4em;
      border-radius: 3px;
      color: #92400e;
      font-weight: 600;
    }
    .icon-large { font-size: 1.8rem; margin-right: 0.8rem; color: #7986cb; }
    .columns { display: flex; gap: 2rem; margin: 1rem 0; }
    .column { flex: 1; }
    .footer { background-color: #f5f7fa; padding: 3rem 1.5rem; margin-top: 4rem; }
    .footer-text { color: #64748b; font-size: 1rem; }
    .footer-text a { color: #3b82f6; text-decoration: none; }
    .footer-text a:hover { text-decoration: underline; }

    @media (max-width: 768px) {
      /* Handles the copy buttons inside the gallery */
      .copy-buttons {
          flex-direction: column;
          width: 100%;
      }
      
      .copy-prompt-btn, .copy-image-btn {
          width: 100%;
          justify-content: center;
      }
      
      .example-footer {
          flex-direction: column;
          align-items: stretch;
          gap: 1rem;
      }
      
      .example-type {
          text-align: center;
      }

      /* Handles the hero buttons with horizontal scrolling */
      .hero .buttons.is-centered {
        /* Force all buttons onto a single line */
        flex-wrap: nowrap;
        
        /* Enable horizontal scrolling if the content overflows */
        overflow-x: auto;
        
        /* Align buttons to the start for a natural scrolling feel */
        justify-content: flex-start;
        
        /* Improve scrolling experience on iOS */
        -webkit-overflow-scrolling: touch;
        
        /* Add a little padding so buttons don't touch the screen edges */
        padding-left: 20px;
        padding-right: 20px;
        padding-bottom: 15px; /* Add space below for a cleaner look */
        
        /* Hide the scrollbar for a cleaner UI */
        scrollbar-width: none; /* For Firefox */
      }

      /* Hide scrollbar for Chrome, Safari, and Opera */
      .hero .buttons.is-centered::-webkit-scrollbar {
        display: none;
      }
    }
</style>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container">
      <div class="has-text-centered">
        <h1 class="title" style="color: #000000;">
          Vision Language Models are Biased
          <img src="static/icons/assumption.png" alt="Bias Icon" class="title-icon">
        </h1>
        
        <div class="is-size-5 publication-authors">
          <span class="author-block"><a href="https://anvo25.github.io/" target="_blank" rel="noopener noreferrer">An Vo</a><sup>1*</sup>,</span>
          <span class="author-block"><a href="https://nkn002.github.io/" target="_blank" rel="noopener noreferrer" >Khai-Nguyen Nguyen</a><sup>2*</sup>,</span>
          <span class="author-block"><a href="https://taesiri.ai/" target="_blank" rel="noopener noreferrer"  >Mohammad Reza Taesiri</a><sup>3</sup>,</span><br class="is-hidden-tablet"> <!-- Optional: only break on smaller screens -->
          <span class="author-block"><a href="https://www.linkedin.com/in/dang-thi-tuong-vy-00a357278/" target="_blank" rel="noopener noreferrer">Vy Tuong Dang</a><sup>1</sup>,</span>
          <span class="author-block"><a href="https://anhnguyen.me/research/" target="_blank" rel="noopener noreferrer" >Anh Totti Nguyen</a><sup>4†</sup>,</span>
          <span class="author-block"><a href="https://www.resl.kaist.ac.kr/members/director" target="_blank" rel="noopener noreferrer">Daeyoung Kim</a><sup>1†</sup></span>
        </div>

        <div class="is-size-5 publication-authors">
          <span class="author-block"><sup>*</sup>Equal contribution                    <sup>†</sup>Equal advising</span><br>
          <span class="author-block"><sup>1</sup>KAIST</span>,
          <span class="author-block"><sup>2</sup>College of William and Mary</span>,
          <span class="author-block"><sup>3</sup>University of Alberta</span>,
          <span class="author-block"><sup>4</sup>Auburn University</span>
        </div>
        
        <div class="mt-4 has-text-centered">
          <div class="buttons is-centered">
            <a href="https://arxiv.org/abs/2505.23941" class="button is-rounded is-dark" target="_blank" rel="noopener noreferrer" onclick="trackPaperDownload()">
              <span class="icon">
                <i class="fas fa-file-pdf"></i>
              </span>
              <span>Paper</span>
            </a>
            <a href="https://github.com/anvo25/vlms-are-biased" class="button is-rounded is-dark" target="_blank" rel="noopener noreferrer" onclick="trackCodeVisit()">
              <span class="icon">
                <i class="fab fa-github"></i>
              </span>
              <span>Code</span>
            </a>
            <a href="https://huggingface.co/datasets/anvo25/vlms-are-biased" class="button is-rounded is-dark" target="_blank" rel="noopener noreferrer" onclick="trackDatasetVisit()">
              <span class="icon">
                <i class="fas fa-database"></i>
              </span>
              <span>Dataset</span>
            </a>

            
            <a href="#example-gallery-section" class="button is-rounded is-examples" onclick="trackExamplesVisit()">
                <span class="icon">
                    <i class="fas fa-play-circle"></i>
                </span>
                <span>Test It Yourself</span>
            </a>
            <a href="https://x.com/anh_ng8/status/1929682381683712340" class="button is-rounded is-discussion" target="_blank" rel="noopener noreferrer" onclick="trackDiscussionVisit()">
              <span class="icon">
                <i class="fas fa-comments"></i>
              </span>
              <span>Discuss with Authors</span>
            </a>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-full-width">
        
        <div class="content-section">
          <!-- MODIFIED: Inline style to reduce top margin -->
          <div class="stat-highlight" style="margin-top: 0.5rem; margin-bottom: 2rem;">
            <p class="is-size-4">
              <strong><i class="fas fa-bullhorn" style="color: #ff6b6b;"></i> Finding:</strong> State-of-the-art Vision Language Models achieve <span class="is-size-3">100%</span> accuracy counting on images of popular subjects (e.g. knowing that the Adidas logo has 3 stripes and a dog has 4 legs) but are only <span class="is-size-3 accuracy-bad">~17%</span> accurate in counting in counterfactual images (e.g. counting stripes in a 4-striped Adidas-like logo or counting legs in a 5-legged dog).
            </p>
            <p class="is-size-5 mt-3">
              <span class="yellow-highlight">VLMs don't actually "see" - they rely on memorized knowledge instead of visual analysis due to bias.</span>
            </p>
          </div>

          <!-- MODIFIED: Added research-figure-medium class -->
          <div class="research-figure research-figure-medium">
            <img src="static/images/fig1_overview.png" alt="VLM failures across 7 domains" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';">
            <div class="image-placeholder" style="display: none; height: 400px;">
              <i class="fas fa-chart-bar"></i>
              <div class="image-title">Figure 1: VLM Failures Overview</div>
              <div class="image-description">VLMs fail on 6 counting tasks and one low-level vision task across seven domains</div>
            </div>
            <div class="figure-caption">
               VLMs fail on 6 counting tasks (a–e & g) and one low-level vision task (f). State-of-the-art models achieve perfect performance on original images but catastrophically fail when objects are subtly modified, defaulting to memorized knowledge rather than actual visual analysis.
            </div>
          </div>
        </div>

        <div class="content-section">
          <h2><i class="fas fa-exclamation-triangle icon-large"></i>The Problem: VLMs Can't Count When It Matters</h2>
          
          <p>
            Imagine asking GPT-4o to count the legs of an animal, and it gets it right every time. Impressive, right? 
            Now imagine adding just <em>one extra leg</em> to that animal and asking again. Suddenly, it fails completely.
          </p>

          <div class="failure-showcase">
            <h3><i class="fas fa-dog"></i> The Dog Experiment</h3>
            <p>
              <strong>Original dog (4 legs):</strong> All models get it right <i class="fas fa-check accuracy-good"></i><br>
              <strong>Same dog with 5 legs:</strong> All models still say "4" <i class="fas fa-times accuracy-bad"></i>
            </p>
            <p>
              They're not counting - they're just recalling "dogs have 4 legs" from their training data.
            </p>
          </div>

          <!-- MODIFIED: Added research-figure-medium class -->
          <div class="research-figure research-figure-medium">
            <img src="static/images/fig3_fail_subtle.png" alt="VLMs fail to detect subtle changes" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';">
            <div class="image-placeholder" style="display: none; height: 350px;">
              <i class="fas fa-times-circle"></i>
              <div class="image-title">Figure 3: Subtle Modification Failures</div>
              <div class="image-description">VLMs fail to detect subtle changes in counterfactuals and default to biased answers</div>
            </div>
            <div class="figure-caption">
              VLMs fail to detect subtle changes in counterfactuals (CF) and default to biased answers. Despite clear visual modifications (extra legs, extra stripes), all models consistently output the expected "normal" values rather than counting what they actually see.
            </div>
          </div>

          <div class="key-insight">
            <p><strong><i class="fas fa-lightbulb"></i> The Core Issue:</strong> VLMs suffer from severe confirmation bias. When they see familiar objects, they default to memorized knowledge instead of performing actual visual analysis. This isn't a minor glitch - it's a fundamental flaw in how these models process visual information.</p>
          </div>
        </div>

        <div class="content-section">
          <h2><i class="fas fa-flask icon-large"></i>How We Test VLM Bias: The VLMBias Framework</h2>
          
          <p>
            Our testing methodology follows a simple but powerful three-step process that exposes the fundamental difference between memorization and actual visual analysis in VLMs.
          </p>

          <!-- MODIFIED: Added research-figure-medium class -->
          <div class="research-figure research-figure-medium">
            <img src="static/images/teaser-1.png" alt="VLMBias testing framework" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';">
            <div class="image-placeholder" style="display: none; height: 450px;">
              <i class="fas fa-microscope"></i>
              <div class="image-title">Figure 2: VLMBias Testing Framework</div>
              <div class="image-description">Three-step methodology: (a) Confirm VLM knowledge, (b) Test on counterfactuals, (c) Analyze bias-relevant backgrounds</div>
            </div>
            <div class="figure-caption">
              Given a subject (e.g., Adidas logo), we first confirm that all VLMs have sufficient knowledge about the subject via ID and counting sanity-check questions (a). Then, we test VLMs on the counterfactual image (b) and report accuracy on counting (Q1 & Q2) and Y/N identification tasks (Q3). For all tasks, we test the hypothesis that visual bias cues in the background (c) may be so strong that they cause VLMs to ignore the modified object and default to biased answers.
            </div>
          </div>

          <div class="columns">
            <div class="column is-6">
              <div class="methodology-section">
                <h3><i class="fas fa-check-circle"></i> Step 1: Sanity Check</h3>
                <p><strong>Confirm VLMs have the knowledge</strong></p>
                <ul>
                  <li><strong>ID Question:</strong> "What shoe logo is this?" → "Adidas" ✓</li>
                  <li><strong>Counting Question:</strong> "How many stripes?" → "3" ✓</li>
                </ul>
                <p><em>Result: 100% accuracy on original images across all models</em></p>
              </div>
            </div>
            <div class="column is-6">
              <div class="methodology-section">
                <h3><i class="fas fa-exclamation-triangle"></i> Step 2: The Bias Test</h3>
                <p><strong>Test on counterfactual images</strong></p>
                <ul>
                  <li><strong>Q1:</strong> "How many visible stripes?" → "3" ✗ (should be "4")</li>
                  <li><strong>Q2:</strong> "Count the visible stripes" → "3" ✗ (should be "4")</li>
                  <li><strong>Q3:</strong> "Is this the Adidas logo?" → "Yes" ✗ (should be "No")</li>
                </ul>
                <p><em>Result: 17.05% average accuracy - catastrophic failure!</em></p>
              </div>
            </div>
          </div>

          <div class="key-insight">
            <p><strong><i class="fas fa-lightbulb"></i> The Critical Insight:</strong> The gap between Step 1 (100% accuracy) and Step 2 (17% accuracy) proves that VLMs are not actually "seeing" - they're retrieving memorized associations. When the visual evidence contradicts their training data, they consistently choose memorized knowledge over what's actually in the image.</p>
          </div>
        </div>

        <div class="content-section">
          <h2><i class="fas fa-images icon-large"></i>Interactive Failure Gallery</h2>
          <p>Explore examples from all 7 domains where state-of-the-art VLMs fail spectacularly.</p>
          
          <div class="slideshow-container">
            <div class="slideshow-header">
              <div class="slideshow-header-content">
                <h3>VLM Failures Across Seven Domains</h3>
                <div class="slideshow-controls">
                  <button class="slide-btn" id="prev-btn" title="Previous slide">
                    <i class="fas fa-chevron-left"></i>
                  </button>
                  <span class="slide-counter">
                    <span id="current-slide">1</span> / <span id="total-slides">7</span>
                  </span>
                  <button class="slide-btn" id="next-btn" title="Next slide">
                    <i class="fas fa-chevron-right"></i>
                  </button>
                </div>
              </div>
            </div>
            
            <div class="slideshow-content">
  
              <div class="slide active" data-domain="Animals">
                <div class="slide-image-container">
                  <div class="slide-image">
                    <img src="static/images/animals_result.png" alt="Dog with 5 legs" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';">
                    <div class="image-placeholder" style="display: none;">
                      <i class="fas fa-paw"></i>
                      <div class="image-title">Task 1: Animals</div>
                      <div class="image-description">Modified Animal Images - Adding extra legs to test counting ability</div>
                    </div>
                  </div>
                  <div class="image-caption">
                    <div class="image-title">Animals with Extra Legs</div>
                    <div class="image-takeaway">Models consistently say "2 legs" for 3-legged birds and "4 legs" for 5-legged mammals.</div>
                  </div>
                </div>
                <div class="slide-content">
                  <div class="domain-tag"><i class="fas fa-paw"></i> Animals</div>
                  <span class="accuracy-indicator">Mean Accuracy: 2.12%</span>
                  <h4>Counting legs in modified animals</h4>
                  <p><strong>Key Finding:</strong> Worst performance domain. Models defaulted to canonical leg counts even when modifications were clearly visible and anatomically plausible.</p>
                </div>
              </div>

              <div class="slide" data-domain="Logos">
                <div class="slide-image-container">
                  <div class="slide-image">
                    <img src="static/images/shoe_logo_result.png" alt="Adidas shoe with 4 stripes" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';">
                    <div class="image-placeholder" style="display: none;">
                      <i class="fas fa-tag"></i>
                      <div class="image-title">Task 2a: Shoe Brand Logos</div>
                      <div class="image-description">Modified shoe logos with extra stripes and curves</div>
                    </div>
                  </div>
                  <div class="image-caption">
                    <div class="image-title">Modified Shoe Logos</div>
                    <div class="image-takeaway">Models default to canonical brand specifications even when logos are clearly modified.</div>
                  </div>
                </div>
                <div class="slide-content">
                  <div class="domain-tag"><i class="fas fa-tag"></i> Shoe Logos</div>
                  <span class="accuracy-indicator">Mean Accuracy: 17.57%</span>
                  <h4>Counting stripes in Adidas shoes and curves in Nike shoes</h4>
                  <p><strong>Key Finding:</strong> Models defaulted to canonical brand specifications. Even when logos were clearly modified and placed in realistic sports contexts, VLMs stuck to memorized brand knowledge.</p>
                </div>
              </div>

              <div class="slide" data-domain="Logos">
                <div class="slide-image-container">
                  <div class="slide-image">
                    <img src="static/images/car_logo_result.png" alt="Audi logo with 5 circles" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';">
                    <div class="image-placeholder" style="display: none;">
                      <i class="fas fa-car"></i>
                      <div class="image-title">Task 2b: Car Brand Logos</div>
                      <div class="image-description">Modified car logos with extra circles and star points</div>
                    </div>
                  </div>
                  <div class="image-caption">
                    <div class="image-title">Modified Car Logos</div>
                    <div class="image-takeaway">Car logos appear smaller making VLMs even more reliant on brand memory.</div>
                  </div>
                </div>
                <div class="slide-content">
                  <div class="domain-tag"><i class="fas fa-car"></i> Car Logos</div>
                  <span class="accuracy-indicator">Mean Accuracy: 0.44%</span>
                  <h4>Counting circles in Audi and points in Mercedes star</h4>
                  <p><strong>Key Finding:</strong> Worst performance in logos category. Small logo size relative to the vehicle made visual bias even stronger - models completely ignored modifications.</p>
                </div>
              </div>

              <div class="slide" data-domain="Flags">
                <div class="slide-image-container">
                  <div class="slide-image">
                    <img src="static/images/flag_result.png" alt="US flag with modified stars" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';">
                    <div class="image-placeholder" style="display: none;">
                      <i class="fas fa-flag"></i>
                      <div class="image-title">Task 3: National Flags</div>
                      <div class="image-description">Modified flags with extra or missing stars and stripes</div>
                    </div>
                  </div>
                  <div class="image-caption">
                    <div class="image-title">Modified National Flags</div>
                    <div class="image-takeaway">Models memorized flag facts rather than counting visible elements.</div>
                  </div>
                </div>
                <div class="slide-content">
                  <div class="domain-tag"><i class="fas fa-flag"></i> National Flags</div>
                  <span class="accuracy-indicator">Mean Accuracy: 9.25%</span>
                  <h4>Counting stripes and stars in modified flags</h4>
                  <p><strong>Key Finding:</strong> Better performance on star counting (11.79%) than stripe counting (4.52%). Stars are spatially separate while stripes are adjacent, making stripe modifications harder to detect.</p>
                </div>
              </div>

              <div class="slide" data-domain="Chess">
                <div class="slide-image-container">
                  <div class="slide-image">
                    <img src="static/images/chess_pieces_result.png" alt="Chess board with 31 pieces" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';">
                    <div class="image-placeholder" style="display: none;">
                      <i class="fas fa-chess"></i>
                      <div class="image-title">Task 4: Chess Pieces</div>
                      <div class="image-description">Chess boards with modified piece counts</div>
                    </div>
                  </div>
                  <div class="image-caption">
                    <div class="image-title">Modified Chess Starting Position</div>
                    <div class="image-takeaway">Models defaulted to standard 32-piece count despite pieces being missing.</div>
                  </div>
                </div>
                <div class="slide-content">
                  <div class="domain-tag"><i class="fas fa-chess"></i> Chess Pieces</div>
                  <span class="accuracy-indicator">Mean Accuracy: 26.25%</span>
                  <h4>Counting pieces on modified starting chess boards</h4>
                  <p><strong>Key Finding:</strong> Best performance counting task, but still heavily biased. Thinking models (o3, o4-mini) significantly outperformed non-thinking models, suggesting explicit reasoning helps detect anomalies.</p>
                </div>
              </div>

              <div class="slide" data-domain="BoardGames">
                <div class="slide-image-container">
                  <div class="slide-image">
                    <img src="static/images/game_board_result.png" alt="10x10 Sudoku grid" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';">
                    <div class="image-placeholder" style="display: none;">
                      <i class="fas fa-dice"></i>
                      <div class="image-title">Task 5: Game Boards</div>
                      <div class="image-description">Game boards with modified grid dimensions</div>
                    </div>
                  </div>
                  <div class="image-caption">
                    <div class="image-title">Modified Game Boards</div>
                    <div class="image-takeaway">Models knew standard dimensions so strongly they couldn't count actual board lines.</div>
                  </div>
                </div>
                <div class="slide-content">
                  <div class="domain-tag"><i class="fas fa-dice"></i> Game Boards</div>
                  <span class="accuracy-indicator">Mean Accuracy: 2.26%</span>
                  <h4>Counting rows/columns in modified game boards</h4>
                  <p><strong>Key Finding:</strong> Worst overall performance. Models scored 0% on Sudoku and Go boards, confirming fundamental inability to perform basic visual counting in structured settings.</p>
                </div>
              </div>

              <div class="slide" data-domain="Illusions">
                <div class="slide-image-container">
                  <div class="slide-image">
                    <img src="static/images/illusion_result.png" alt="Modified Ebbinghaus illusion" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';">
                    <div class="image-placeholder" style="display: none;">
                      <i class="fas fa-eye"></i>
                      <div class="image-title">Task 6: Optical Illusions</div>
                      <div class="image-description">Original and modified optical illusions</div>
                    </div>
                  </div>
                  <div class="image-caption">
                    <div class="image-title">Modified Optical Illusions</div>
                    <div class="image-takeaway">VLMs knew illusion patterns but failed when effects were reversed.</div>
                  </div>
                </div>
                <div class="slide-content">
                  <div class="domain-tag"><i class="fas fa-eye"></i> Optical Illusions</div>
                  <span class="accuracy-indicator">Mean Accuracy: 50.87%</span>
                  <h4>Comparing elements in original vs. modified illusions</h4>
                </div>
              </div>

              <div class="slide" data-domain="Grids">
                <div class="slide-image-container">
                  <div class="slide-image">
                    <img src="static/images/patterned_grid_result.png" alt="Grid pattern with anomalous cell" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';">
                    <div class="image-placeholder" style="display: none;">
                      <i class="fas fa-th"></i>
                      <div class="image-title">Task 7: Patterned Grids</div>
                      <div class="image-description">Grid patterns with anomalous cells</div>
                    </div>
                  </div>
                  <div class="image-caption">
                    <div class="image-title">Anomalous Grid Patterns</div>
                    <div class="image-takeaway">Models prioritized pattern completion over visual counting even in novel contexts.</div>
                  </div>
                </div>
                <div class="slide-content">
                  <div class="domain-tag"><i class="fas fa-th"></i> Patterned Grids</div>
                  <span class="accuracy-indicator">Mean Accuracy: 22.44%</span>
                  <h4>Counting elements in anomalous grid cells</h4>
                  <p><strong>Key Finding:</strong> Even with novel patterns never seen before, VLMs inferred expected values from surrounding cells rather than counting actual elements in the target cell.</p>
                </div>
              </div>

            </div>
            
            <div class="slideshow-footer">
              <div class="domain-indicators">
                <span class="domain-indicator active" data-domain="all"><span>All Tasks</span></span>
                <span class="domain-indicator" data-domain="Animals"><span><i class="fas fa-paw"></i> Animals</span></span>
                <span class="domain-indicator" data-domain="Logos"><span><i class="fas fa-tag"></i> Logos</span></span>
                <span class="domain-indicator" data-domain="Flags"><span><i class="fas fa-flag"></i> Flags</span></span>
                <span class="domain-indicator" data-domain="Chess"><span><i class="fas fa-chess"></i> Chess</span></span>
                <span class="domain-indicator" data-domain="BoardGames"><span><i class="fas fa-dice"></i> Boards</span></span>
                <span class="domain-indicator" data-domain="Illusions"><span><i class="fas fa-eye"></i> Illusions</span></span>
                <span class="domain-indicator" data-domain="Grids"><span><i class="fas fa-th"></i> Grids</span></span>
              </div>
              <div class="slideshow-info">
                <p><i class="fas fa-info-circle"></i> Slideshow auto-advances every 3 seconds. Click domain tags to filter examples or use arrow keys for navigation.</p>
              </div>
            </div>
          </div>
        </div>

      <div class="content-section" id="example-gallery-section">
        <div class="gallery-section">
          <div class="gallery-header">
            <h2><i class="fas fa-vial" style="margin-right: 0.8rem;"></i>Example Gallery</h2>
            <p style="font-size: 1rem; opacity: 0.9; margin-top: 0.5rem;">Please feel free to copy the prompts and test with your own VLMs.</p>
          </div>
          
          <div class="gallery-container" id="gallery-container">
            <div class="gallery-paused" id="gallery-paused">
              <i class="fas fa-pause"></i> Paused
            </div>
            <div class="gallery-nav prev" id="gallery-prev">
              <i class="fas fa-chevron-left"></i>
            </div>
            <div class="gallery-nav next" id="gallery-next">
              <i class="fas fa-chevron-right"></i>
            </div>
            <div class="gallery-viewport" id="gallery-viewport">
              <!-- Gallery items will be populated by JavaScript -->
              <div class="gallery-loading" style="display: flex; justify-content: center; align-items: center; height: 400px; color: #666;">
                <i class="fas fa-spinner fa-spin" style="margin-right: 0.5rem;"></i>
                Loading gallery...
              </div>
            </div>
          </div>
          
          <div class="gallery-filters" id="gallery-filters">
            <!-- Filter buttons will be populated by JavaScript -->
            <div class="filters-loading" style="text-align: center; padding: 1rem; color: #666;">
              Loading filters...
            </div>
          </div>
          
          <div class="gallery-indicators" id="gallery-indicators">
            <!-- Indicators will be populated by JavaScript -->
          </div>
        </div>
      </div>

        <div class="content-section">
          <h2><i class="fas fa-chart-bar icon-large"></i>The Bias is Systematic, Not Random</h2>
          <p>When VLMs make errors, they don't make random mistakes. Instead, 75.70% of all errors are "bias-aligned" - meaning they give the expected answer based on prior knowledge rather than what they actually see in the image.</p>
          
          <div class="research-figure research-figure-medium">
            <img src="static/images/bias-error.png" alt="Bias-aligned errors across domains" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';">
            <div class="image-placeholder" style="display: none; height: 200px; width: 80%;">
              <i class="fas fa-chart-line"></i>
              <div class="image-title">Bias-aligned errors across domains</div>
              <div class="image-description">Systematic pattern of bias-aligned errors proving models ignore visual evidence</div>
            </div>
            <div class="figure-caption">
              On counterfactual images, VLMs mostly output answers that match biased choices rather than random errors. This systematic pattern proves models actively ignore visual evidence in favor of memorized knowledge.
            </div>
          </div>

          <div class="key-insight">
            <p><strong><i class="fas fa-target"></i> This is the smoking gun:</strong> If models were simply bad at vision, we'd expect random errors. Instead, we see systematic bias toward "correct" textbook answers, proving they're overriding visual information with memorized facts.</p>
          </div>
        </div>

        <div class="content-section">
          <h2><i class="fas fa-chart-bar icon-large"></i>All Models Fail Equally</h2>
          <p>We tested five state-of-the-art models. The results are consistently terrible across the board:</p>
          
          <div class="research-table">
            <div class="table-content">
              <div class="comparison-table">
                <table>
                  <caption style="font-size: 1.1rem; color: #333; padding: 1rem; text-align: left; line-height: 1.6;">
                    All VLMs achieve <span class="truth-value">100%</span> on identification and counting tasks with unmodified images, showing that they fully recognize the original version but fail on the counting questions on the modified images (i.e., counterfactuals) in VLMBias. The mean accuracy of five state-of-the-art VLMs on our seven tasks is <span class="error-value">17.05%</span>. o4-mini achieves the highest accuracy (20.25%) which however is still low. VLMs with "thinking" capabilities (o4-mini, o3) only slightly outperform non-thinking models (Gemini-2.5 Pro, Sonnet-3.7, GPT-4.1).
                  </caption>
                  <thead>
                    <tr>
                      <th rowspan="2">Model</th>
                      <th colspan="7">Accuracy in counting questions (Q1 & Q2) on counterfactual images (%)</th>
                      <th rowspan="2">Task mean (CF) (%)</th>
                      <th rowspan="2">Task mean (Unmodified) (%)</th>
                    </tr>
                    <tr>
                      <th><i class="fas fa-paw"></i> Animal</th>
                      <th><i class="fas fa-tag"></i> Logo</th>
                      <th><i class="fas fa-flag"></i> Flag</th>
                      <th><i class="fas fa-chess"></i> Chess</th>
                      <th><i class="fas fa-dice"></i> Board</th>
                      <th><i class="fas fa-eye"></i> Illusion</th>
                      <th><i class="fas fa-th"></i> Grid</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>Gemini-2.5 Pro</td>
                      <td>0.00</td>
                      <td>1.96</td>
                      <td>10.42</td>
                      <td>26.74</td>
                      <td>2.38</td>
                      <td>49.81</td>
                      <td>20.83</td>
                      <td>16.02</td>
                      <td>100.00</td>
                    </tr>
                    <tr>
                      <td>Sonnet-3.7</td>
                      <td>0.00</td>
                      <td>2.72</td>
                      <td>13.75</td>
                      <td>9.03</td>
                      <td>1.79</td>
                      <td class="best-value">54.29</td>
                      <td class="best-value">34.52</td>
                      <td>16.59</td>
                      <td>100.00</td>
                    </tr>
                    <tr>
                      <td>GPT-4.1</td>
                      <td class="best-value">9.52</td>
                      <td class="best-value">9.07</td>
                      <td>2.50</td>
                      <td>8.68</td>
                      <td>0.00</td>
                      <td>48.61</td>
                      <td>18.75</td>
                      <td>13.88</td>
                      <td>100.00</td>
                    </tr>
                    <tr>
                      <td>o3</td>
                      <td>0.92</td>
                      <td>7.60</td>
                      <td>5.00</td>
                      <td>42.71</td>
                      <td>2.38</td>
                      <td>50.38</td>
                      <td>20.54</td>
                      <td>18.50</td>
                      <td>100.00</td>
                    </tr>
                    <tr>
                      <td>o4-mini</td>
                      <td>0.18</td>
                      <td>9.31</td>
                      <td class="best-value">14.58</td>
                      <td class="best-value">44.10</td>
                      <td class="best-value">4.76</td>
                      <td>51.26</td>
                      <td>17.56</td>
                      <td class="best-value">20.25</td>
                      <td>100.00</td>
                    </tr>
                    <tr style="background: #f8fafc;">
                      <td style="font-weight: 700;">Mean</td>
                      <td>2.12</td>
                      <td>6.13</td>
                      <td>9.25</td>
                      <td>26.25</td>
                      <td>2.26</td>
                      <td>50.87</td>
                      <td>22.44</td>
                      <td class="highlight-value">17.05</td>
                      <td>100.00</td>
                    </tr>
                  </tbody>
                </table>
              </div>
            </div>
          </div>

          <div class="key-insight">
            <p><strong><i class="fas fa-target"></i> Key Finding:</strong> 75.70% of all errors were "bias-aligned" - meaning models gave the expected answer based on prior knowledge rather than random mistakes. This proves they're not just bad at vision; they're actively ignoring what they see.</p>
          </div>
        </div>

        <div class="content-section">
          <h2><i class="fas fa-lightbulb icon-large"></i>Why This Matters</h2>
          
          <div class="columns">
            <div class="column is-6">
              <div class="failure-showcase">
                <h3><i class="fas fa-exclamation-triangle"></i> Immediate Concerns</h3>
                <ul>
                  <li><strong>Medical Imaging:</strong> Missing tumors that don't match training patterns.</li>
                  <li><strong>Autonomous Vehicles:</strong> Failing to see modified road signs.</li>
                  <li><strong>Quality Control:</strong> Missing defects in manufactured goods.</li>
                  <li><strong>Security:</strong> Fooled by simple visual modifications.</li>
                  <li><strong>Website/App Control:</strong> If user interfaces change subtly (buttons, layouts, or icons), biased models may fail to perform tasks correctly, unable to adapt to minor visual modifications.</li>
                </ul>
              </div>
            </div>
            <div class="column is-6">
              <div class="key-insight">
                <h3><i class="fas fa-lightbulb"></i> Deeper Implications</h3>
                <ul>
                  <li><strong>False Confidence:</strong> Models are wrong but certain.</li>
                  <li><strong>Brittleness:</strong> Tiny changes cause complete failure.</li>
                  <li><strong>Training Flaws:</strong> Memorization over understanding.</li>
                  <li><strong>Evaluation Gap:</strong> Benchmarks miss real-world failure modes.</li>
                </ul>
              </div>
            </div>
          </div>

          <div class="stat-highlight">
            <h3><i class="fas fa-search"></i> The Bottom Line</h3>
            <p class="is-size-4">
              Current VLMs are sophisticated pattern matching systems, not visual reasoning systems. 
              They excel at recognizing familiar patterns but fail catastrophically when those patterns are even slightly modified.
            </p>
          </div>
        </div>

        <div class="content-section">
          <h2><i class="fas fa-tools icon-large"></i>What We Tried (That Didn't Work)</h2>
          
          <p>We tested two approaches to help models perform better. Neither worked significantly:</p>
          
          <div class="results-grid">
            <div class="model-result">
              <h4><i class="fas fa-search"></i> "Double-Check"</h4>
              <p><strong>Prompt:</strong> "Please double-check your answer and give your final answer in curly brackets, following the format above."</p>
              <p><strong>Improvement:</strong> <span class="accuracy-bad">+2.70% (Mean)</span></p>
            </div>
            <div class="model-result">
              <h4><i class="fas fa-target"></i> "Debiased Prompts"</h4>
              <p><strong>Prompt:</strong> "Do not assume from prior knowledge and answer only based on what is visible in the image."</p>
              <p><strong>Improvement:</strong> <span class="accuracy-bad">+1.87% (Mean)</span></p>
            </div>
          </div>

          <div class="quote-block">
            <p><strong>Sobering Reality:</strong> Even with explicit instructions to ignore prior knowledge and focus on visual details, models barely improved. The bias is deeply embedded in how they process visual information.</p>
          </div>
        </div>

        <div class="content-section">
          <h2><i class="fas fa-font icon-large"></i>Adversarial In-Image Text Makes It Even Worse</h2>
          
          <p>Adding subject names directly to images (like "Ebbinghaus illusion") made models even more biased, dropping accuracy by an additional 4.49%.</p>

          <div class="research-figure research-figure-medium" id="adversarial-text-figure">
            <img src="static/images/add_title.png" alt="In-image text example showing Ebbinghaus illusion"  onerror="this.style.display='none'; this.parentElement.insertAdjacentHTML('afterbegin', '<div class=\'image-placeholder\'><i class=\'fas fa-image\'></i><div class=\'image-title\'>Ebbinghaus Illusion with Text</div><div class=\'image-description\'>Image showing Ebbinghaus illusion variants with added text labels.</div></div>');">
            <div class="figure-caption">
              Original vs. modified versions without (top) and with (bottom) the in-image text ("Ebbinghaus illusion"). Adding text labels makes models more likely to rely on memorized knowledge rather than visual analysis.
            </div>
          </div>

          <div class="failure-showcase">
            <h3><i class="fas fa-font"></i> Text Labels Increase Bias</h3>
            <p><strong>Effect:</strong> <span class="accuracy-bad">-4.49% accuracy drop</span> when subject names were added to images.</p>
            <p><strong>Worse for thinking models:</strong> o4-mini (-6.56), o3 (-6.41) vs. Sonnet-3.7 (-2.81), GPT-4.1 (-2.67).</p>
            <p>This suggests that more sophisticated reasoning can sometimes amplify bias when textual cues are present.</p>
          </div>
        </div>

        <div class="content-section">
          <h2><i class="fas fa-road icon-large"></i>What Comes Next?</h2>
          
          <div class="key-insight">
            <h3><i class="fas fa-target"></i> Immediate Actions Needed</h3>
            <p>
              The AI community needs to acknowledge that current VLMs have fundamental limitations. 
              We need better evaluation methods that test actual visual reasoning, not just pattern recognition.
            </p>
          </div>

          <div class="columns">
            <div class="column is-6">
              <h3><i class="fas fa-flask"></i> Research Directions</h3>
              <ul>
                <li>Develop training methods that emphasize visual analysis over memorization.</li>
                <li>Create evaluation benchmarks that test robustness to modifications.</li>
                <li>Build models that can explicitly separate prior knowledge from visual evidence.</li>
                <li>Investigate multi-modal reasoning architectures.</li>
              </ul>
            </div>
            <div class="column is-6">
              <h3><i class="fas fa-cogs"></i> Practical Solutions</h3>
              <ul>
                <li>Implement uncertainty quantification for visual tasks.</li>
                <li>Develop hybrid systems combining vision models with explicit counting modules.</li>
                <li>Create domain-specific fine-tuning approaches.</li>
                <li>Build better human-AI collaboration interfaces.</li>
              </ul>
            </div>
          </div>
        </div>

        <div class="content-section">
          <h2><i class="fas fa-flag-checkered icon-large"></i>The Takeaway</h2>
          
          <div class="stat-highlight">
            <p class="is-size-3 has-text-weight-bold">VLMs aren't as smart as we thought.</p>
            <p class="is-size-5">
              They're incredibly sophisticated at recognizing patterns they've seen before, 
              but they fundamentally lack the ability to perform basic visual analysis when faced with novel variations.
            </p>
          </div>

          <div class="key-insight">
            <p>
              <strong>This research reveals a critical blind spot in AI development.</strong> 
              As we deploy these systems in high-stakes applications, we must understand their limitations. 
              A model that can describe complex scenes but can't count legs on a modified animal is not truly "seeing" - 
              it's performing very sophisticated pattern matching.
            </p>
          </div>

          <div class="quote-block">
            <p class="is-size-5">
              "The most dangerous thing about current VLMs isn't that they fail - it's that they fail confidently, 
              giving no indication that they're relying on memorized knowledge rather than actual visual analysis."
            </p>
          </div>
        </div>

      </div>
    </div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8 has-text-centered">
        <p class="footer-text">
          This website is adapted from <a href="https://nerfies.github.io">Nerfies</a>.
        </p>
      </div>
    </div>
  </div>
</footer>

<script>
// Combined functionality - Run when DOM is ready
document.addEventListener('DOMContentLoaded', function() {
  console.log('DOM loaded, initializing components...');
  initializeSlideshow();
  initializeGallery();
  setupSmoothScrolling();
});

// ===== EXAMPLE GALLERY FUNCTIONALITY =====
function initializeGallery() {
  console.log('Initializing gallery...');
  
  const galleryData = [
    { task: "Animals", image: "static/images/examples/task1_animals/2_legs/chicken_0_3_1152.png", question: "How many legs does this animal have? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "3", expectedBias: "2", icon: "fas fa-paw" },
    { task: "Animals", image: "static/images/examples/task1_animals/2_legs/duck_0_3_1152.png", question: "How many legs does this animal have? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "3", expectedBias: "2", icon: "fas fa-paw" },
    { task: "Animals", image: "static/images/examples/task1_animals/4_legs/zebra_5_3_1152.png", question: "How many legs does this animal have? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "5", expectedBias: "4", icon: "fas fa-paw" },
    { task: "Animals", image: "static/images/examples/task1_animals/4_legs/african elephant_2_0_1152.png", question: "How many legs does this animal have? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "5", expectedBias: "4", icon: "fas fa-paw" },
    { task: "Logos", image: "static/images/examples/task2_logos/car_logos/audi-black-convertible_1152.png", question: "How many overlapping circles are there in the logo of this car? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "5", expectedBias: "4", icon: "fas fa-tag" },
    { task: "Logos", image: "static/images/examples/task2_logos/car_logos/mercedes_benz-black-coupe_1152.png", question: "How many points are there on the star in the logo of this car? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "4", expectedBias: "3", icon: "fas fa-tag" },
    { task: "Logos", image: "static/images/examples/task2_logos/shoe_logos/adidas-black-basketball-5_1152.png", question: "How many visible stripes are there in the logo of the left shoe? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "4", expectedBias: "3", icon: "fas fa-tag" },
    { task: "Logos", image: "static/images/examples/task2_logos/shoe_logos/adidas-red-running-5_1152.png", question: " How many visible stripes are there in the logo of the left shoe? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "4", expectedBias: "3", icon: "fas fa-tag" },
    { task: "Flags", image: "static/images/examples/task3_flags/stripes/Flag of the United States-stripes=12_1152.png", question: "How many stripes are there on this flag? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "12", expectedBias: "13", icon: "fas fa-flag" },
    { task: "Flags", image: "static/images/examples/task3_flags/stripes/Flag of the United States-stripes=14_1152.png", question: "How many stripes are there on this flag? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "14", expectedBias: "13", icon: "fas fa-flag" },
    { task: "Flags", image: "static/images/examples/task3_flags/stars/Flag of Europe-stars=11_1152.png", question: "How many stars are there on this flag? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "11", expectedBias: "12", icon: "fas fa-flag" },
    { task: "Flags", image: "static/images/examples/task3_flags/stars/Flag of Europe-stars=13_1152.png", question: "How many stars are there on this flag? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "13", expectedBias: "12", icon: "fas fa-flag" },
    { task: "Chess Pieces", image: "static/images/examples/task4_chess_pieces/chess/chess_pieces_005_remove_whiteking_at_e1_notitle_px1152.png", question: "How many chess pieces are there on this board? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "31", expectedBias: "32", icon: "fas fa-chess" },
    { task: "Chess Pieces", image: "static/images/examples/task4_chess_pieces/chess/chess_pieces_008_remove_blackbishop_at_f8_notitle_px1152.png", question: "How many chess pieces are there on this board? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "31", expectedBias: "32", icon: "fas fa-chess" },
    { task: "Chess Pieces", image: "static/images/examples/task4_chess_pieces/xiangqi/xiangqi_pieces_002_remove_black_soldier_at_e4_notitle_px1152.png", question: "How many xiangqi pieces are there on this board? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "31", expectedBias: "32", icon: "fas fa-chess" },
    { task: "Chess Pieces", image: "static/images/examples/task4_chess_pieces/xiangqi/xiangqi_pieces_006_remove_red_chariot_at_i10_notitle_px1152.png", question: "How many xiangqi pieces are there on this board? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "31", expectedBias: "32", icon: "fas fa-chess" },
    { task: "Game Boards", image: "static/images/examples/task5_game_boards/chess/chess_grid_02_row_remove_last_row_notitle_px1152.png", question: "How many rows are there on this board? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "7", expectedBias: "8", icon: "fas fa-dice" },
    { task: "Game Boards", image: "static/images/examples/task5_game_boards/go/go_grid_03_add_row_px1152.png", question: "How many horizontal lines are there on this board? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "20", expectedBias: "19", icon: "fas fa-dice" },
    { task: "Game Boards", image: "static/images/examples/task5_game_boards/sudoku/sudoku_grid_08_col_remove_last_col_notitle_px1152.png", question: "How many columns are there on this puzzle? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "8", expectedBias: "9", icon: "fas fa-dice" },
    { task: "Game Boards", image: "static/images/examples/task5_game_boards/xiangqi/xiangqi_grid_02_row_remove_row_after_river_notitle_px1152.png", question: "How many horizontal lines are there on this board? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "9", expectedBias: "10", icon: "fas fa-dice" },
    { task: "Optical Illusions", image: "static/images/examples/task6_optical_illusion/ebbinghaus/Ebbinghaus_017_str3_diff0p7_notitle_px1152.png", question: "Are the two inner circles equal in size? Answer in curly brackets, e.g., {Yes} or {No}.", groundTruth: "No", expectedBias: "Yes", icon: "fas fa-eye" },
    { task: "Optical Illusions", image: "static/images/examples/task6_optical_illusion/muller_lyer/MullerLyer_023_str50_diff0p5_notitle_px1152.png", question: "Are the two horizontal lines equal in length? Answer in curly brackets, e.g., {Yes} or {No}.", groundTruth: "No", expectedBias: "Yes", icon: "fas fa-eye" },
    { task: "Optical Illusions", image: "static/images/examples/task6_optical_illusion/zollner/Zollner_022_strneg75_diffneg2p5_notitle_px1152.png", question: "Are the two horizontal lines parallel? Answer in curly brackets, e.g., {Yes} or {No}.", groundTruth: "No", expectedBias: "Yes", icon: "fas fa-eye" },
    { task: "Optical Illusions", image: "static/images/examples/task6_optical_illusion/ponzo/Ponzo_023_str18_diff0p25_notitle_px1152.png", question: "Are the two horizontal lines equal in length? Answer in curly brackets, e.g., {Yes} or {No}.", groundTruth: "No", expectedBias: "Yes", icon: "fas fa-eye" },
    { task: "Patterned Grids", image: "static/images/examples/task7_patterned_grid/dice/dice_001_remove_C3_notitle_px1152.png", question: "How many circles are there in cell C3? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "2", expectedBias: "3", icon: "fas fa-th" },
    { task: "Patterned Grids", image: "static/images/examples/task7_patterned_grid/dice/dice_001_replace_C3_notitle_px1152.png", question: "How many circles are there in cell C3? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "2", expectedBias: "3", icon: "fas fa-th" },
    { task: "Patterned Grids", image: "static/images/examples/task7_patterned_grid/tally/tally_003_add_D4_notitle_px1152.png", question: "How many lines are there in cell D4? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "5", expectedBias: "4", icon: "fas fa-th" },
    { task: "Patterned Grids", image: "static/images/examples/task7_patterned_grid/tally/tally_003_remove_D4_notitle_px1152.png", question: "How many lines are there in cell D4? Answer with a number in curly brackets, e.g., {9}.", groundTruth: "3", expectedBias: "4", icon: "fas fa-th" }
  ];

  const galleryContainer = document.getElementById('gallery-container');
  const filtersContainer = document.getElementById('gallery-filters');
  const viewport = document.getElementById('gallery-viewport');
  const indicatorsContainer = document.getElementById('gallery-indicators');
  const prevBtn = document.getElementById('gallery-prev');
  const nextBtn = document.getElementById('gallery-next');

  if (!galleryContainer || !filtersContainer || !viewport || !indicatorsContainer) {
    console.error('Gallery elements not found');
    return;
  }
  
  // *** FIX #1: Detect if the user is on a touch device ***
  const isTouchDevice = ('ontouchstart' in window) || (navigator.maxTouchPoints > 0) || (navigator.msMaxTouchPoints > 0);

  let categories = [];
  let currentCategoryIndex = 0;
  let autoSlideInterval;
  let isPaused = false;

  function setup() {
    categories = [...new Set(galleryData.map(item => item.task))];
    createFilterButtons();
    createIndicators();
    
    prevBtn.addEventListener('click', () => changeCategory(-1));
    nextBtn.addEventListener('click', () => changeCategory(1));
    
    // *** FIX #1: Conditional event listeners for pause/play ***
    if (isTouchDevice) {
        // On mobile, use tap to toggle pause/play
        galleryContainer.addEventListener('click', (e) => {
            // Make sure the click is not on a button
            if (!e.target.closest('button')) {
                if (isPaused) {
                    isPaused = false;
                    startAutoPlay();
                } else {
                    pauseAutoPlay();
                }
            }
        });
    } else {
        // On desktop, use hover to pause/play
        galleryContainer.addEventListener('mouseenter', pauseAutoPlay);
        galleryContainer.addEventListener('mouseleave', () => {
            isPaused = false;
            startAutoPlay();
        });
    }
    
    window.addEventListener('resize', () => displayCategory(currentCategoryIndex));
    
    displayCategory(0);
  }

  function createFilterButtons() {
    const taskIcons = { 'Animals': 'fas fa-paw', 'Logos': 'fas fa-tag', 'Flags': 'fas fa-flag', 'Chess Pieces': 'fas fa-chess', 'Game Boards': 'fas fa-dice', 'Optical Illusions': 'fas fa-eye', 'Patterned Grids': 'fas fa-th' };
    filtersContainer.innerHTML = '';
    categories.forEach((task, index) => {
      const button = document.createElement('button');
      button.className = 'gallery-filter-btn';
      button.innerHTML = `<i class="${taskIcons[task] || 'fas fa-circle'}"></i> ${task}`;
      button.dataset.index = index;
      button.addEventListener('click', () => displayCategory(index));
      filtersContainer.appendChild(button);
    });
  }

  function createIndicators() {
    indicatorsContainer.innerHTML = '';
    categories.forEach((_, index) => {
      const indicator = document.createElement('div');
      indicator.className = 'gallery-indicator';
      indicator.addEventListener('click', () => displayCategory(index));
      indicatorsContainer.appendChild(indicator);
    });
  }

  function displayCategory(index) {
    clearInterval(autoSlideInterval); // Stop timer during transition
    currentCategoryIndex = index;

    viewport.style.opacity = '0';

    setTimeout(() => {
        const categoryName = categories[index];
        const activeData = galleryData.filter(item => item.task === categoryName);
        const itemsPerView = getItemsPerView();
        
        viewport.innerHTML = '';
        const track = document.createElement('div');
        track.className = 'gallery-track';
        const slide = document.createElement('div');
        slide.className = 'gallery-slide';

        for (let i = 0; i < Math.min(itemsPerView, activeData.length); i++) {
            const item = activeData[i];
            const galleryItem = document.createElement('div');
            galleryItem.className = 'gallery-item';
            const gapValue = '1.5rem';
            galleryItem.style.width = `calc((100% - (${itemsPerView - 1} * ${gapValue})) / ${itemsPerView})`;

            galleryItem.innerHTML = `
              <div class="example-card">
                <div class="example-image">
                  <img src="${item.image}" alt="${item.task} example" loading="lazy">
                  <div class="image-fallback"><i class="fas fa-exclamation-triangle"></i><span>Image not found</span></div>
                </div>
                <div class="example-content">
                  <p class="example-question">${item.question}</p>
                  <div class="example-info">
                    <span><span class="info-label truth-label">Ground Truth:</span><span class="info-value truth-value">${item.groundTruth}</span></span>
                    <span><span class="info-label bias-label">Bias:</span><span class="info-value bias-value">${item.expectedBias}</span></span>
                  </div>
                  <div class="example-footer">
                    <span class="example-type"><i class="${item.icon}"></i> ${item.task}</span>
                    <div class="copy-buttons">
                      <button class="copy-prompt-btn" data-prompt="${item.question.replace(/"/g, '"')}"><i class="fas fa-copy"></i> Copy Prompt</button>
                      <button class="copy-image-btn" data-image="${item.image}"><i class="fas fa-image"></i> Copy Image</button>
                    </div>
                  </div>
                </div>
              </div>`;
            const img = galleryItem.querySelector('img');
            img.addEventListener('error', () => galleryItem.querySelector('.example-image').classList.add('has-error'));
            slide.appendChild(galleryItem);
        }
        
        track.appendChild(slide);
        viewport.appendChild(track);
        
        viewport.style.opacity = '1';
        updateActiveUI();
        startAutoPlay(); 
    }, 300); 
  }
  
  function updateActiveUI() {
      document.querySelectorAll('.gallery-filter-btn').forEach((btn, index) => {
          btn.classList.toggle('active', index === currentCategoryIndex);
      });
      document.querySelectorAll('.gallery-indicator').forEach((dot, index) => {
          dot.classList.toggle('active', index === currentCategoryIndex);
      });
  }

  function changeCategory(direction) {
    const newIndex = (currentCategoryIndex + direction + categories.length) % categories.length;
    displayCategory(newIndex);
  }

  function startAutoPlay() {
    if (isPaused) return;
    clearInterval(autoSlideInterval);
    autoSlideInterval = setInterval(() => changeCategory(1), 5000);
  }

  function pauseAutoPlay() {
    isPaused = true;
    clearInterval(autoSlideInterval);
  }
  
  function getItemsPerView() {
    if (window.innerWidth <= 768) return 1;
    if (window.innerWidth <= 1024) return 2;
    return 4;
  }

  galleryContainer.addEventListener('click', async function(e) {
    const promptButton = e.target.closest('.copy-prompt-btn');
    if (promptButton) {
      const promptText = promptButton.dataset.prompt;
      navigator.clipboard.writeText(promptText).then(() => {
        const originalText = promptButton.innerHTML;
        promptButton.innerHTML = '<i class="fas fa-check"></i> Copied!';
        promptButton.classList.add('copied');
        setTimeout(() => {
          promptButton.innerHTML = originalText;
          promptButton.classList.remove('copied');
        }, 2000);
      });
    }
    
    const imageButton = e.target.closest('.copy-image-btn');
    if (imageButton) {
      const imageUrl = imageButton.dataset.image;
      
      // *** FIX #2: Conditional logic for "Copy Image" button ***
      if (isTouchDevice) {
        // On mobile, open image in a new tab for easy saving
        window.open(imageUrl, '_blank');
      } else {
        // On desktop, use the Clipboard API
        imageButton.innerHTML = '<i class="fas fa-spinner fa-spin"></i>'; 
        try {
          const response = await fetch(imageUrl);
          const blob = await response.blob();
          await navigator.clipboard.write([ new ClipboardItem({ [blob.type]: blob }) ]);
          
          const originalText = '<i class="fas fa-image"></i> Copy Image';
          imageButton.innerHTML = '<i class="fas fa-check"></i> Copied!';
          imageButton.classList.add('copied');
          setTimeout(() => {
            imageButton.innerHTML = originalText;
            imageButton.classList.remove('copied');
          }, 2000);
        } catch (err) {
          console.error('Failed to copy image: ', err);
          alert('Could not copy image. Your browser may not support this feature or there was a network error.');
          imageButton.innerHTML = '<i class="fas fa-times"></i> Failed';
        }
      }
    }
  });

  // Start everything
  setup();
}


// ===== SLIDESHOW FUNCTIONALITY =====
function initializeSlideshow() {
  console.log('Initializing slideshow...');
  
  const allSlides = document.querySelectorAll('.slide');
  if (allSlides.length === 0) {
    console.log('No slides found, skipping slideshow initialization');
    return;
  }

  let currentSlideIndex = 0;
  let slideInterval;
  let filteredSlides = Array.from(allSlides);
  let isPaused = false;
  const isTouchDevice = ('ontouchstart' in window) || (navigator.maxTouchPoints > 0);

  function showSlide(index) {
    const slideshowContent = document.querySelector('.slideshow-content');
    if (!slideshowContent) return;

    if (filteredSlides.length === 0) {
      if (!slideshowContent.querySelector('.no-slides-message')) {
        const noSlidesDiv = document.createElement('div');
        noSlidesDiv.className = 'no-slides-message';
        noSlidesDiv.innerHTML = '<p style="text-align:center; padding:2rem;">No examples match this filter.</p>';
        slideshowContent.appendChild(noSlidesDiv);
      }
      updateSlideCounter(0, 0);
      return;
    }
    
    const existingMessage = slideshowContent.querySelector('.no-slides-message');
    if (existingMessage) existingMessage.remove();

    currentSlideIndex = (index + filteredSlides.length) % filteredSlides.length;
    filteredSlides.forEach((slide, i) => slide.classList.toggle('active', i === currentSlideIndex));
    updateSlideCounter(currentSlideIndex + 1, filteredSlides.length);
  }

  function changeSlide(direction) {
    showSlide(currentSlideIndex + direction);
  }

  function startAutoSlide() {
    clearInterval(slideInterval);
    if (!isPaused && filteredSlides.length > 1) { 
      slideInterval = setInterval(() => changeSlide(1), 3000);
    }
  }

  function stopAutoSlide() { 
    clearInterval(slideInterval); 
  }

  function updateSlideCounter(current, total) {
    const currentElement = document.getElementById('current-slide');
    const totalElement = document.getElementById('total-slides');
    if (currentElement && totalElement) {
      currentElement.textContent = current;
      totalElement.textContent = total;
    }
  }

  function filterByDomain(domain) {
    allSlides.forEach(slide => slide.classList.remove('active'));
    
    document.querySelectorAll('.domain-indicator').forEach(indicator => {
      indicator.classList.remove('active');
    });
    const activeIndicator = document.querySelector(`.domain-indicator[data-domain="${domain}"]`);
    if (activeIndicator) activeIndicator.classList.add('active');

    filteredSlides = (domain === 'all') 
      ? Array.from(allSlides) 
      : Array.from(allSlides).filter(slide => slide.getAttribute('data-domain') === domain);
    
    showSlide(0);
    startAutoSlide();
  }

  const slideshow = document.querySelector('.slideshow-container');
  if (slideshow) {
      if(isTouchDevice) {
          slideshow.addEventListener('click', (e) => {
              if(!e.target.closest('button, a')) {
                  isPaused ? startAutoSlide() : stopAutoSlide();
                  isPaused = !isPaused;
              }
          });
      } else {
        slideshow.addEventListener('mouseenter', stopAutoSlide);
        slideshow.addEventListener('mouseleave', startAutoSlide);
      }
  }
  
  const prevBtn = document.getElementById('prev-btn');
  const nextBtn = document.getElementById('next-btn');
  
  if (prevBtn) prevBtn.addEventListener('click', e => { e.preventDefault(); changeSlide(-1); startAutoSlide(); });
  if (nextBtn) nextBtn.addEventListener('click', e => { e.preventDefault(); changeSlide(1); startAutoSlide(); });
  
  document.querySelectorAll('.domain-indicator').forEach(indicator => {
    indicator.addEventListener('click', e => filterByDomain(e.currentTarget.getAttribute('data-domain')));
  });
  
  document.addEventListener('keydown', e => {
    const isSlideshowFocused = document.activeElement && document.activeElement.closest('.slideshow-container');
    if (isSlideshowFocused) {
      if (e.key === 'ArrowLeft') { e.preventDefault(); changeSlide(-1); startAutoSlide();}
      else if (e.key === 'ArrowRight') { e.preventDefault(); changeSlide(1); startAutoSlide();}
    }
  });

  showSlide(0);
  startAutoSlide();
  
  console.log('Slideshow initialization complete');
}

// ===== SMOOTH SCROLLING =====
function setupSmoothScrolling() {
  document.querySelectorAll('a[href^="#"]').forEach(anchor => {
    anchor.addEventListener('click', function (e) {
      e.preventDefault();
      const targetElement = document.querySelector(this.getAttribute('href'));
      if (targetElement) {
        targetElement.scrollIntoView({ behavior: 'smooth' });
      }
    });
  });
}
</script>

</body>
</html>